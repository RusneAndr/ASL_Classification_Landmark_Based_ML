# ASL_Classification_Landmark_Based_ML
ASL Hand Gesture Classification with MediaPipe Landmarks   SVM (96.60%) + RNN (74.83%) on 27 static ASL gestures (A–Z + space + del). 63-dimensional hand landmarks, to real-time recognition at ~30 FPS with smoothing.  Outperforms previous image-based CNN (92%) while using 200× fewer features.

This project presents a landmark-based approach for static American Sign Language (ASL) hand gesture recognition using machine learning. Hand keypoint coordinates extracted with MediaPipe are used to represent each gesture with only 63 features, enabling efficient and robust classification. Support Vector Machine (SVM) and Long Short-Term Memory (LSTM) models are evaluated, with the SVM achieving a test accuracy of 96.60% and outperforming the LSTM on this static recognition task. The system operates in real time with temporal smoothing and demonstrates improved accuracy and robustness compared to a previous image-based CNN approach, while reducing input dimensionality by over 200×. The results highlight the effectiveness of well-engineered landmark features combined with classical machine learning for practical ASL recognition systems.
